# eye-spy-nlp
EyeSpy - Leveraging NLP to Extract Key Information from Ophthalmology Clinic Notes



## Background/Introduction
The growing use of electronic medical records (EMRs) has led to the accumulation of vast amounts of patient data, including free-text medical notes. Despite the wealth of information contained in these notes, extracting relevant data in a structured manner can be a daunting task. Natural Language Processing (NLP) techniques can help extract valuable information from these notes. We had two primary data sources we worked off of for all of the following tasks. The first was a Kaggle dataset of medical notes related to ophthalmology. The second was from an ongoing research study under Dr. Joshua Stein at the Kellogg Eye Institute, which required IRB approval. Any tasks related to the second dataset were performed in a virtual sandbox on a secure drive in order to maintain appropriate research conduct. 

## Task A: Binary Classification
This portion of our project involved two subtasks. For the first task, our team used ophthalmology notes from a Kaggle dataset to create a binary classification model to aid in identifying the diagnosis of cataracts accurately and efficiently. The second task involved creating another binary classification model using data from the Kellogg Eye Center to identify the diagnosis of glaucoma.
The data was split into training and validation sets and pre-processed using the BertTokenizer. The data was trained using BERT (Bidirectional Encoder Representations from Transformers) classification with an AdamW optimizer.  BERT can be particularly useful in the classification of medical notes to identify the presence or absence of a particular disease. Our team used validation loss and validation accuracy evaluation methods when evaluating the results of each epoch. Our final accuracy was 0.81 without hyper parameter optimization. A limitation that exists for this task is the relatively small dataset used to train our cataract classification model. There were a total of 83 ophthalmology notes available in the Kaggle dataset and 17 of the 83 notes included cataract diagnosis. Future work on this task would include working with an expanded data set and creating additional models for other ophthalmology conditions such as diabetic retinopathy or macular degeneration. 
The second task was a simple Voting Classifier model performed on the research dataset containing over 2 million records. The goal was to correctly classify four potential glaucoma outcomes: glaucoma in left eye, no glaucoma in left eye, glaucoma in right eye, or no glaucoma in right eye. We created two models to classify right and left eye separately. Without optimization and with feature engineering, accuracy was around 0.93 for right eye and 0.91 for left eye. The class break down of each groups is to the right. OD is right eye, OS is left. 

## Task B: Heading Classification
Unstructured clinical notes may contain one or more capitalized subsection headings (e.g. DIAGNOSIS), offering an extractable, semi-structured schema in the content of the note; the clinical text and its subsection heading can be structured as a heading classification task to learn and help identify appropriate headings for unlabeled clinical notes. 
	The dataset from Kaggle contained 84 ophthalmology transcription notes containing 340 Non-Empty subsections with 90 unique headings retrieved using a regex rule. In preparation for a heading classification task, the 84 ophthalmology transcription notes were then reorganized as 340 heading:text pairs with each extracted heading functioning as a class label. However, to reduce the total number of classes to train in a clinical note heading classifier, the 90 unique headings were reviewed and aggregated according to their semantic and functional content into 11 final class labels (e.g. CHIEF COMPLAINT -> SUBJECTIVE, REASON FOR VISIT -> SUBJECTIVE). The DIAGNOSIS and PROCEDURE labels accounted for nearly two thirds of the all class labels with the other 9 labels accounting for the remaining third. Thus, the final prepared dataset contained 340 clinical ophthalmology notes with each note mapped to one of the eleven finalized heading class labels.
	For the training and evaluation of a multi-class heading classifier, notes were tokenized and then organized into training, validation and test sets according to a 60/20/20 split. A pre-trained BERT model was then fine-tuned using the training and validation sets using three epochs to achieve the final model used in the evaluation of the test data. The final weighted average of F1-scores was .67 with the highest scores belonging to the recall of DIAGNOSIS notes and the recall of PROCEDURE notes - both a score of 1. Given the heavy imbalance of the 11 classes with a heavy skew of support towards the DIAGNOSIS and PROCEDURE classes, five classes had only one case each in the test set and scores of zero across all metrics. Thus, the model tended towards false positives of classes with higher support, which would likely be ameliorated with a larger and more balanced dataset.


## Task C: Named Entity Recognition
Two different methodologies were used to extract disease names from ophthalmology notes. The first involved a dataset from Kaggle that contained 84 clinical assessment notes. These notes were loaded as a batch into Metamap with settings to include the CUI and limit semantic types to only diseases. From this output, a lookup table for ophthalmology diseases and their corresponding CUI was created. Out of 323 diseases identified, 22 fell into the 10 ophthalmology CUI categories we had identified in our lookup table. A breakdown can be seen in the charts below. For the second methodology, the set of 50 available progress notes from Michigan Medicine was used. For this method, a findall regex expression was used in conjunction with a list of ophthalmological diseases to extract disease names.



## Task D: Rule-Based Extraction
	This part of the project involved taking the ophthalmology notes from Kaggle that were labeled as Diagnosis notes by the heading classification part of the project and determining the laterality of the eye (right, left, both) based on the diagnosis notes. This was fairly straightforward to approach with a rule-based approach using regex. For the left eye, “OS” or “left” was checked for in a note. For the right eye, “OD” or “right” was checked for in a note. For both eyes, only “bilateral” was mentioned rather than “OU”, so we limited this to bilateral. Ultimately, we categorized the laterality of each diagnosis note to be “right eye”, “left eye”, “both eyes”, or “unspecified”. There were 108 diagnosis notes and 51 were classified to be the right eye, 10 were classified to be the left eye, 4 were classified to be both eyes, and 43 were classified to be “unspecified”. A limitation that existed was the data being overly anonymized. For example, several notes listed eye laterality as “xxx” (redacted) rather than “os” (left), “od” (right”), or “ou” (“both”). As a result, many notes were unspecified in laterality. 

For the next step of this task, the Kellogg dataset progress notes from Michigan Medicine were used instead of diagnosis notes from Kaggle. To preprocess the progress notes text data, an updated pipeline was incorporated into the script that was previously used for the kaggle dataset. The preprocessing pipeline converted text to lowercase, splitted it into individual words, removed all punctuation marks and digits using regular expressions, replaced newline characters with spaces, applied stemming to reduce each word to its root form, and also removed any remaining stopwords using a set provided by the nltk library. These steps effectively cleaned and transformed the raw text data into a more meaningful and useful format for applying regex to extract laterality.

The dataset comprising 7100 rows, which was created for the binary classification of glaucoma task, was used to extract laterality. Unlike the kaggle’s diagnosis dataset, this data was not aggressively anonymized, and out of the 7100 notes, only 707 were unspecified while the rest of the notes were labeled with laterality successfully.
